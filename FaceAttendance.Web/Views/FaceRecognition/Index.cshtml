<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection</title>
    <script src="js/face-api.min.js"></script>
    <script src="js/tsf.js"></script>
    <style>
        video {
            width: 640px;
            height: 480px;
            position: relative;
            z-index: 1;
        }

        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 2;
        }
    </style>
</head>
<body>
    <div style="position: relative; width: 640px; height: 480px;">
        <video id="video" autoplay></video>
        <canvas id="canvas"></canvas>
    </div>

    <div class="row">
        <div class="col-lg-12">
            <img id="captured" class="border-1" style="width:200px; height:220px" />
            <p id="name"></p>
        </div>
    </div>
    <script>
        async function loadModels() {
            try {
                await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
                await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
                console.log("Models loaded successfully");
            } catch (error) {
                console.error("Error loading models: ", error);
            }
        }

        async function startVideo() {
            const video = document.getElementById('video');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;

                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        video.play();
                        resolve();
                    };
                });
            } catch (error) {
                console.error("Error accessing the camera: ", error);
                alert("Could not access the camera. Please ensure you have granted permissions.");
            }
        }

        async function GetInfo() {
            fetch('/FaceRecognition/GetEmployeeInfo', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
            })
                .then(response => response.json()) // Parse the JSON response
                .then(data => {
                    console.log("Employees:", data);
                    // Use the data (e.g., update the DOM)
                })
                .catch(error => {
                    console.error("Error:", error);
                });
        }

        async function recordTime(employeeName) {
            try {
                const response = await fetch('/FaceRecognition/RecordTime', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(employeeName), // Send the employee name as a JSON string
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! Status: ${response.status}`);
                }

                const data = await response.json();
                console.log('Success:', data);
            } catch (error) {
                console.error('Error:', error);
            }
        }

        async function loadLabeledImages() {
            try {
                // Fetch employee data from the server
                const response = await fetch('/FaceRecognition/GetEmployeeInfo', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' }
                });

                const employees = await response.json();
                const labeledDescriptors = [];

                // Loop through all employees
                for (const employee of employees) {
                    try {
                        // 1. Convert Base64/byte[] to an HTML image element
                        const img = await loadImage(employee.employeePhoto);

                        // 2. Detect face in the image
                        const detection = await faceapi
                            .detectSingleFace(img)
                            .withFaceLandmarks()
                            .withFaceDescriptor();

                        if (!detection) {
                            console.warn(`No face detected for ${employee.employeeName}`);
                            continue; // Skip this employee
                        }

                        // 3. Save the descriptor
                        labeledDescriptors.push(
                            new faceapi.LabeledFaceDescriptors(
                                employee.employeeName,
                                [detection.descriptor]
                            )
                        );
                    } catch (error) {
                        console.error(`Error processing ${employee.employeeName}:`, error);
                    }
                }

                return labeledDescriptors;
            } catch (error) {
                console.error("Failed to load labeled images:", error);
                return [];
            }
        }

        // Helper function to load images from Base64/byte[]
        function loadImage(photoData) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.src = `data:image/jpeg;base64,${photoData}`; // Assumes photo is Base64
                img.onload = () => resolve(img);
                img.onerror = (err) => reject(err);
            });
        }

        async function recognizeFaces(labeledDescriptors) {
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const capturedElement = document.getElementById('captured');
            
            const displaySize = { width: video.videoWidth, height: video.videoHeight };
            canvas.width = displaySize.width;
            canvas.height = displaySize.height;

            const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.42);

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptors();

                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);

                faceapi.draw.drawDetections(canvas, resizedDetections);


                if (resizedDetections.length > 0) {
                    resizedDetections.forEach(detection => {
                        const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
                        const { x, y } = detection.detection.box;
                        const ctx = canvas.getContext('2d');

                        // Ensure the bounding box properties are correctly accessed
                        const box = detection.detection.box;

                        const width = box.width;
                        const height = box.height;


                        ctx.font = '20px Arial';
                        ctx.fillStyle = 'red';
                        ctx.fillText(bestMatch.label, x + 40, y - 5);

                        // Capture the face from the video
                        const faceCanvas = document.createElement('canvas');
                        faceCanvas.width = width;
                        faceCanvas.height = height;
                        const faceCtx = faceCanvas.getContext('2d');
                        faceCtx.drawImage(video, x, y, width, height, 0, 0, width, height);

                        

                        //document.getElementById('captured').src = faceCanvas.toDataURL('image/jpeg');
                        if (bestMatch.label != 'unknown') {
                            document.getElementById('name').textContent = bestMatch.label;
                            
                            // Display the captured face in the 'captured' element
                            capturedElement.src = faceCanvas.toDataURL('image/jpeg');

                            recordTime(bestMatch.label);


                        }
                    });
                } else {
                    document.getElementById('name').textContent = "No face detected";
                    // Display the captured face in the 'captured' element
                    capturedElement.src = "";
                }
            }, 100);
        }

        (async () => {
            await loadModels();
            const labeledDescriptors = await loadLabeledImages();
            await startVideo();
            recognizeFaces(labeledDescriptors);
        })();
    </script>
</body>
</html>
