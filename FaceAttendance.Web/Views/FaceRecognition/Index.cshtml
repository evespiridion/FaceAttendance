<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection with face-api.js</title>
    <script src="~/js/face-api.min.js"></script>
    <script src="~/js/tsf.js"></script>
    <style>
        video {
            width: 640px;
            height: 480px;
            position: relative;
            z-index: 1;
        }

        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 2;
        }
    </style>
</head>
<body>
    <div style="position: relative; width: 640px; height: 480px;">
        <video id="video" autoplay></video>
        <canvas id="canvas"></canvas>
    </div>
    <!--test-->
    <script>
        // Load models
        async function loadModels() {
            try {
                await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
                console.log("Models loaded successfully");
            } catch (error) {
                console.error("Error loading models: ", error);
            }
        }

        async function startVideo() {
            const video = document.getElementById('video');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
            } catch (error) {
                console.error("Error accessing the camera: ", error);
                alert("Could not access the camera. Please ensure you have granted permissions.");
            }
        }

        async function detectFaces() {
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');

            // Ensure the video has started before setting the interval
            video.addEventListener('loadedmetadata', () => {
                const displaySize = { width: video.videoWidth, height: video.videoHeight };
                faceapi.matchDimensions(canvas, displaySize);

                setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                    faceapi.draw.drawDetections(canvas, resizedDetections);
                    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
                }, 100);
            });
        }

        // Initialize everything
        (async () => {
            await loadModels();
            await startVideo();
            detectFaces();
        })();
    </script>
</body>
</html>
